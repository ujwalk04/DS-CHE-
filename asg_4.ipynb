{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(1) # set a seed so that the results are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9568, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>V</th>\n",
       "      <th>AP</th>\n",
       "      <th>RH</th>\n",
       "      <th>PE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.96</td>\n",
       "      <td>41.76</td>\n",
       "      <td>1024.07</td>\n",
       "      <td>73.17</td>\n",
       "      <td>463.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.18</td>\n",
       "      <td>62.96</td>\n",
       "      <td>1020.04</td>\n",
       "      <td>59.08</td>\n",
       "      <td>444.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.11</td>\n",
       "      <td>39.40</td>\n",
       "      <td>1012.16</td>\n",
       "      <td>92.14</td>\n",
       "      <td>488.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.86</td>\n",
       "      <td>57.32</td>\n",
       "      <td>1010.24</td>\n",
       "      <td>76.64</td>\n",
       "      <td>446.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.82</td>\n",
       "      <td>37.50</td>\n",
       "      <td>1009.23</td>\n",
       "      <td>96.62</td>\n",
       "      <td>473.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>16.65</td>\n",
       "      <td>49.69</td>\n",
       "      <td>1014.01</td>\n",
       "      <td>91.00</td>\n",
       "      <td>460.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9564</th>\n",
       "      <td>13.19</td>\n",
       "      <td>39.18</td>\n",
       "      <td>1023.67</td>\n",
       "      <td>66.78</td>\n",
       "      <td>469.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>31.32</td>\n",
       "      <td>74.33</td>\n",
       "      <td>1012.92</td>\n",
       "      <td>36.48</td>\n",
       "      <td>429.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9566</th>\n",
       "      <td>24.48</td>\n",
       "      <td>69.45</td>\n",
       "      <td>1013.86</td>\n",
       "      <td>62.39</td>\n",
       "      <td>435.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9567</th>\n",
       "      <td>21.60</td>\n",
       "      <td>62.52</td>\n",
       "      <td>1017.23</td>\n",
       "      <td>67.87</td>\n",
       "      <td>453.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9568 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AT      V       AP     RH      PE\n",
       "0     14.96  41.76  1024.07  73.17  463.26\n",
       "1     25.18  62.96  1020.04  59.08  444.37\n",
       "2      5.11  39.40  1012.16  92.14  488.56\n",
       "3     20.86  57.32  1010.24  76.64  446.48\n",
       "4     10.82  37.50  1009.23  96.62  473.90\n",
       "...     ...    ...      ...    ...     ...\n",
       "9563  16.65  49.69  1014.01  91.00  460.03\n",
       "9564  13.19  39.18  1023.67  66.78  469.62\n",
       "9565  31.32  74.33  1012.92  36.48  429.57\n",
       "9566  24.48  69.45  1013.86  62.39  435.74\n",
       "9567  21.60  62.52  1017.23  67.87  453.28\n",
       "\n",
       "[9568 rows x 5 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data - Sheet1.csv\")\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[463.26, 444.37, 488.56, ..., 429.57, 435.74, 453.28]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.filter([\"AT\", \"V\", \"AP\",\"RH\"])\n",
    "X=X.to_numpy()\n",
    "Y=df.filter(['PE'])\n",
    "Y=Y.to_numpy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "Y.reshape(1,9568)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7654, 4), (7654, 1), (1914, 4), (1914, 1))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0.0\n",
    "    return w, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head\n",
    "y_head = sigmoid(0)\n",
    "y_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(w,b,x_train,y_train):\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z) # probabilistic 0-1\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    return cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]      # x_train.shape[1]  is for scaling\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1] # x_train.shape[1]  is for scaling\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]                 # x_train.shape[1]  is for scaling\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate,number_of_iteration):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    # updating(learning) parameters is number_of_iteration times\n",
    "    for i in range(number_of_iteration):\n",
    "        # make forward and backward propagation and find cost and gradients\n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        # lets update\n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    # we update(learn) parameters weights and bias\n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    # x_test is a input for forward propagation\n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    # if z is bigger than 0.5, our prediction is sign one (y_head=1),\n",
    "    # if z is smaller than 0.5, our prediction is sign zero (y_head=0),\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1,7654) and (1914,4) not aligned: 7654 (dim 1) != 1914 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\college\\ds-che\\asg_4.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dimension \u001b[39m=\u001b[39m  X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m w,b \u001b[39m=\u001b[39m initialize_weights_and_bias(dimension)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m predict(w,b,X_test)\n",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\college\\ds-che\\asg_4.ipynb Cell 11\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(w, b, x_test)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(w,b,x_test):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# x_test is a input for forward propagation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     z \u001b[39m=\u001b[39m sigmoid(np\u001b[39m.\u001b[39;49mdot(w\u001b[39m.\u001b[39;49mT,x_test)\u001b[39m+\u001b[39mb)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     Y_prediction \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39m1\u001b[39m,x_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# if z is bigger than 0.5, our prediction is sign one (y_head=1),\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# if z is smaller than 0.5, our prediction is sign zero (y_head=0),\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,7654) and (1914,4) not aligned: 7654 (dim 1) != 1914 (dim 0)"
     ]
    }
   ],
   "source": [
    "dimension =  X_train.shape[0]\n",
    "w,b = initialize_weights_and_bias(dimension)\n",
    "predict(w,b,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan\\AppData\\Local\\Temp\\ipykernel_29620\\1409177709.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: -inf\n",
      "Cost after iteration 10: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\college\\ds-che\\asg_4.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m100\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mabs(y_prediction_train \u001b[39m-\u001b[39m y_train)) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtest accuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m100\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39mabs(y_prediction_test \u001b[39m-\u001b[39m y_test)) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m logistic_regression(X_train, y_train, X_test, y_test,learning_rate \u001b[39m=\u001b[39;49m \u001b[39m0.0001\u001b[39;49m, num_iterations \u001b[39m=\u001b[39;49m \u001b[39m150\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\college\\ds-che\\asg_4.ipynb Cell 11\u001b[0m in \u001b[0;36mlogistic_regression\u001b[1;34m(x_train, y_train, x_test, y_test, learning_rate, num_iterations)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m w,b \u001b[39m=\u001b[39m initialize_weights_and_bias(dimension)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# do not change learning rate\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m parameters, gradients, cost_list \u001b[39m=\u001b[39m update(w, b, x_train, y_train, learning_rate,num_iterations)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_prediction_test \u001b[39m=\u001b[39m predict(parameters[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m],parameters[\u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m],x_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_prediction_train \u001b[39m=\u001b[39m predict(parameters[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m],parameters[\u001b[39m\"\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m\"\u001b[39m],x_train)\n",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\college\\ds-che\\asg_4.ipynb Cell 11\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(w, b, x_train, y_train, learning_rate, number_of_iteration)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# updating(learning) parameters is number_of_iteration times\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(number_of_iteration):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m# make forward and backward propagation and find cost and gradients\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     cost,gradients \u001b[39m=\u001b[39m forward_backward_propagation(w,b,x_train,y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     cost_list\u001b[39m.\u001b[39mappend(cost)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# lets update\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\rohan\\Desktop\\college\\ds-che\\asg_4.ipynb Cell 11\u001b[0m in \u001b[0;36mforward_backward_propagation\u001b[1;34m(w, b, x_train, y_train)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cost \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39msum(loss))\u001b[39m/\u001b[39mx_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]      \u001b[39m# x_train.shape[1]  is for scaling\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# backward propagation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m derivative_weight \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39;49mdot(x_train,((y_head\u001b[39m-\u001b[39;49my_train)\u001b[39m.\u001b[39;49mT)))\u001b[39m/\u001b[39;49mx_train\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m# x_train.shape[1]  is for scaling\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m derivative_bias \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(y_head\u001b[39m-\u001b[39my_train)\u001b[39m/\u001b[39mx_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]                 \u001b[39m# x_train.shape[1]  is for scaling\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/rohan/Desktop/college/ds-che/asg_4.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m gradients \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mderivative_weight\u001b[39m\u001b[39m\"\u001b[39m: derivative_weight,\u001b[39m\"\u001b[39m\u001b[39mderivative_bias\u001b[39m\u001b[39m\"\u001b[39m: derivative_bias}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    # initialize\n",
    "    dimension =  x_train.shape[0]  # that is 4096\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "    # do not change learning rate\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(X_train, y_train, X_test, y_test,learning_rate = 0.01, num_iterations = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b8ec01fe1ca8fb45588a4ccd1c70e5bbb495e4fae5c72e85a541e07ce265118"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
